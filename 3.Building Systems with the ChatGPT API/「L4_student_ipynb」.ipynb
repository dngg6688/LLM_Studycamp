{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dngg6688/LLM_Studycamp/blob/main/3.Building%20Systems%20with%20the%20ChatGPT%20API/%E3%80%8CL4_student_ipynb%E3%80%8D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e7531d5-0c22-49ad-9d37-8b08eec7d4e0",
      "metadata": {
        "id": "0e7531d5-0c22-49ad-9d37-8b08eec7d4e0"
      },
      "source": [
        "# L4: Process Inputs: Chain of Thought Reasoning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e613f6af-ce1c-49ea-ae99-0d2e3fa3fae1",
      "metadata": {
        "id": "e613f6af-ce1c-49ea-ae99-0d2e3fa3fae1"
      },
      "source": [
        "## Setup\n",
        "#### Load the API key and relevant Python libaries.\n",
        "In this course, we've provided some code that loads the OpenAI API key for you."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scuabonhELOd",
        "outputId": "43acc244-2651-4145-e691-f8d0fb6b012c"
      },
      "id": "scuabonhELOd",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0df1c9e8",
      "metadata": {
        "height": 132,
        "id": "0df1c9e8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "# from dotenv import load_dotenv, find_dotenv\n",
        "# _ = load_dotenv(find_dotenv())\n",
        "from google.colab import userdata\n",
        "openai.api_key  = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b98a05b6",
      "metadata": {
        "height": 183,
        "id": "b98a05b6"
      },
      "outputs": [],
      "source": [
        "def get_completion_from_messages(messages,\n",
        "                                 model=\"gpt-3.5-turbo\",\n",
        "                                 temperature=0, max_tokens=500):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "119d273f-df72-47e2-a9a6-a8994d742aec",
      "metadata": {
        "id": "119d273f-df72-47e2-a9a6-a8994d742aec"
      },
      "source": [
        "## Chain-of-Thought Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e0e66beb-8fb5-4c7b-afa7-13d20ded1d49",
      "metadata": {
        "height": 1543,
        "id": "e0e66beb-8fb5-4c7b-afa7-13d20ded1d49"
      },
      "outputs": [],
      "source": [
        "delimiter = \"####\"\n",
        "system_message = f\"\"\"\n",
        "Follow these steps to answer the customer queries.\n",
        "The customer query will be delimited with four hashtags,\\\n",
        "i.e. {delimiter}.\n",
        "\n",
        "Step 1:{delimiter} First decide whether the user is \\\n",
        "asking a question about a specific product or products. \\\n",
        "Product cateogry doesn't count.\n",
        "\n",
        "Step 2:{delimiter} If the user is asking about \\\n",
        "specific products, identify whether \\\n",
        "the products are in the following list.\n",
        "All available products:\n",
        "1. Product: TechPro Ultrabook\n",
        "   Category: Computers and Laptops\n",
        "   Brand: TechPro\n",
        "   Model Number: TP-UB100\n",
        "   Warranty: 1 year\n",
        "   Rating: 4.5\n",
        "   Features: 13.3-inch display, 8GB RAM, 256GB SSD, Intel Core i5 processor\n",
        "   Description: A sleek and lightweight ultrabook for everyday use.\n",
        "   Price: $799.99\n",
        "\n",
        "2. Product: BlueWave Gaming Laptop\n",
        "   Category: Computers and Laptops\n",
        "   Brand: BlueWave\n",
        "   Model Number: BW-GL200\n",
        "   Warranty: 2 years\n",
        "   Rating: 4.7\n",
        "   Features: 15.6-inch display, 16GB RAM, 512GB SSD, NVIDIA GeForce RTX 3060\n",
        "   Description: A high-performance gaming laptop for an immersive experience.\n",
        "   Price: $1199.99\n",
        "\n",
        "3. Product: PowerLite Convertible\n",
        "   Category: Computers and Laptops\n",
        "   Brand: PowerLite\n",
        "   Model Number: PL-CV300\n",
        "   Warranty: 1 year\n",
        "   Rating: 4.3\n",
        "   Features: 14-inch touchscreen, 8GB RAM, 256GB SSD, 360-degree hinge\n",
        "   Description: A versatile convertible laptop with a responsive touchscreen.\n",
        "   Price: $699.99\n",
        "\n",
        "4. Product: TechPro Desktop\n",
        "   Category: Computers and Laptops\n",
        "   Brand: TechPro\n",
        "   Model Number: TP-DT500\n",
        "   Warranty: 1 year\n",
        "   Rating: 4.4\n",
        "   Features: Intel Core i7 processor, 16GB RAM, 1TB HDD, NVIDIA GeForce GTX 1660\n",
        "   Description: A powerful desktop computer for work and play.\n",
        "   Price: $999.99\n",
        "\n",
        "5. Product: BlueWave Chromebook\n",
        "   Category: Computers and Laptops\n",
        "   Brand: BlueWave\n",
        "   Model Number: BW-CB100\n",
        "   Warranty: 1 year\n",
        "   Rating: 4.1\n",
        "   Features: 11.6-inch display, 4GB RAM, 32GB eMMC, Chrome OS\n",
        "   Description: A compact and affordable Chromebook for everyday tasks.\n",
        "   Price: $249.99\n",
        "\n",
        "Step 3:{delimiter} If the message contains products \\\n",
        "in the list above, list any assumptions that the \\\n",
        "user is making in their \\\n",
        "message e.g. that Laptop X is bigger than \\\n",
        "Laptop Y, or that Laptop Z has a 2 year warranty.\n",
        "\n",
        "Step 4:{delimiter}: If the user made any assumptions, \\\n",
        "figure out whether the assumption is true based on your \\\n",
        "product information.\n",
        "\n",
        "Step 5:{delimiter}: First, politely correct the \\\n",
        "customer's incorrect assumptions if applicable. \\\n",
        "Only mention or reference products in the list of \\\n",
        "5 available products, as these are the only 5 \\\n",
        "products that the store sells. \\\n",
        "Answer the customer in a friendly tone.\n",
        "\n",
        "Use the following format:\n",
        "Step 1:{delimiter} <step 1 reasoning>\n",
        "Step 2:{delimiter} <step 2 reasoning>\n",
        "Step 3:{delimiter} <step 3 reasoning>\n",
        "Step 4:{delimiter} <step 4 reasoning>\n",
        "Response to user:{delimiter} <response to customer>\n",
        "\n",
        "Make sure to include {delimiter} to separate every step.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6be1ea0a-a816-4694-8a79-77d985f2e274",
      "metadata": {
        "height": 234,
        "id": "6be1ea0a-a816-4694-8a79-77d985f2e274",
        "outputId": "c0d39c8d-7a9b-474d-80f8-98ec1ce94249",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1:#### The user is asking about the price difference between the BlueWave Chromebook and the TechPro Desktop.\n",
            "\n",
            "Step 2:#### Both the BlueWave Chromebook and the TechPro Desktop are available products.\n",
            "\n",
            "Step 3:#### The user assumes that the BlueWave Chromebook is more expensive than the TechPro Desktop.\n",
            "\n",
            "Step 4:#### The assumption made by the user is incorrect. The TechPro Desktop is priced at $999.99, while the BlueWave Chromebook is priced at $249.99. Therefore, the BlueWave Chromebook is actually less expensive than the TechPro Desktop.\n",
            "\n",
            "Response to user:#### The BlueWave Chromebook is actually less expensive than the TechPro Desktop. The BlueWave Chromebook is priced at $249.99, while the TechPro Desktop is priced at $999.99.\n"
          ]
        }
      ],
      "source": [
        "user_message = f\"\"\"\n",
        "by how much is the BlueWave Chromebook more expensive \\\n",
        "than the TechPro Desktop\"\"\"\n",
        "\n",
        "messages =  [\n",
        "{'role':'system',\n",
        " 'content': system_message},\n",
        "{'role':'user',\n",
        " 'content': f\"{delimiter}{user_message}{delimiter}\"},\n",
        "]\n",
        "\n",
        "response = get_completion_from_messages(messages)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f51afe6d",
      "metadata": {
        "height": 183,
        "id": "f51afe6d",
        "outputId": "dcfa3676-2dee-42f6-e838-15dd39a3ec84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1:#### The user is asking if the store sells TVs.\n",
            "\n",
            "Step 2:#### The user is not asking about specific products, but rather about a product category. TVs are not included in the list of available products.\n",
            "\n",
            "Response to user:#### I'm sorry, but we do not sell TVs. Our store specializes in computers and laptops. If you have any questions about our available products, feel free to ask.\n"
          ]
        }
      ],
      "source": [
        "user_message = f\"\"\"\n",
        "do you sell tvs\"\"\"\n",
        "messages =  [\n",
        "{'role':'system',\n",
        " 'content': system_message},\n",
        "{'role':'user',\n",
        " 'content': f\"{delimiter}{user_message}{delimiter}\"},\n",
        "]\n",
        "response = get_completion_from_messages(messages)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a552a4f6-5e65-4d85-9579-5263f720aa10",
      "metadata": {
        "id": "a552a4f6-5e65-4d85-9579-5263f720aa10"
      },
      "source": [
        "## Inner Monologue\n",
        "- Since we asked the LLM to separate its reasoning steps by a delimiter, we can hide the chain-of-thought reasoning from the final output that the user sees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2a825237",
      "metadata": {
        "height": 115,
        "id": "2a825237",
        "outputId": "0872abab-3397-4a68-acdf-82505fe4dc31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but we do not sell TVs. Our store specializes in computers and laptops. If you have any questions about our available products, feel free to ask.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    final_response = response.split(delimiter)[-1].strip()\n",
        "except Exception as e:\n",
        "    final_response = \"Sorry, I'm having trouble right now, please try asking another question.\"\n",
        "\n",
        "print(final_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7470753",
      "metadata": {
        "height": 30,
        "id": "f7470753"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}